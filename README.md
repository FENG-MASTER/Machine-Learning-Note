# 学习进度 #

>所有进度在我博客里都有详细的笔记 传送门:http://blog.leanote.com/cate/fengmaster/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0

## 第一周(10.24-10.29) ##
>由于我之前从来没有了解过机器学习相关的东西,我甚至连机器学习是干嘛的都不知道,所以一切从0开始

### 10.24 ###

首先我查阅了一些入门资料,但大部分资料都建立在有一定基础上才能看的懂,后来转向了入门资料的查找,不约而同的都指向了斯坦福大学的Andrew Ng在coursera上的关于机器学习的入门基础视频教程

https://www.coursera.org/learn/machine-learning

(好吧,翻墙实在是慢,最近由于我们的XXX,搞的梯子都不好用了,推荐下[b站的搬运视频](https://www.bilibili.com/video/av9912938/)[而且翻译比coursera全面])


但我看了下coursera上的课程安排,一共11周,时间太长了,打算尽可能快的学习完毕,具体速度看这几天的学习情况再定

#### 学习内容 ####

coursera第一周上半部分

1. 大致上了解了机器学习所做的领域和作用
2. 了解了监督学习( Supervised learning )和非监督学习的定义和一些例子
3. 了解了类聚算法,分类算法的作用
4. 复习了一下微积分的基础概念和简单计算

### 10.25 ###

继续coursera的课程第一周的下半部分

1. 学习了解了监督学习中的回归问题
2. 学习了解了代价函数(cost function)的定义和作用
3. 学习了解了假设函数的定义和作用
4. 学习了解了单个参数下线性回归问题(梯度下降法)的简单思考过程
5. 复习了线代中矩阵部分的基础知识

### 10.26 ###

继续coursera的课程第二周上半部分

1. 学习了解了特征缩放的使用和使用场景
2. 学习了解了归一化的使用和使用场景
3. 学习了解了多项式回归的使用
4. 了解了什么叫数据拟合
5. 初步了解了正规方程法
6. 了解了正规方程法和梯度下降法的优点和缺点,和适用的场景

### 10.27-10.28 ###

继续coursera课程第二周下半部分

1. 了解coursera的语法

### 10.29 ###

1.完成第二周编程作业:线性回归问题,并且完成了附加部分(多参数)


### 10.30-11.5 ###

有事在忙,现在还没更新,进度比原来慢了点,因为有几天有事. 

### 11.6-11.7 ###

>小手术住院啦,进度慢了点

完成coursera的课程第三周的学习

1. 学习了解了二元分类算法
2. 学习了解了多元分类算法
3. 了解了一些高级的优化算法的使用

### 11.8 ###

随便找个博客,开始入手了解下推荐系统(我也不知道这个毕业设计本质上是不是推荐系统,个人觉得挺像)

[基于内容的推荐（Content-based Recommendations）](https://www.cnblogs.com/breezedeus/archive/2012/04/10/2440488.html)


[协同过滤算法](http://blog.csdn.net/acdreamers/article/details/44672305) 


### 11.9 ###

学习了coursera的过拟合部分