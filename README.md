# 学习进度 #

>所有进度在我博客里都有详细的笔记 传送门:http://blog.leanote.com/cate/fengmaster/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0

## 第一周(10.24-10.29) ##
>由于我之前从来没有了解过机器学习相关的东西,我甚至连机器学习是干嘛的都不知道,所以一切从0开始

### 10.24 ###

首先我查阅了一些入门资料,但大部分资料都建立在有一定基础上才能看的懂,后来转向了入门资料的查找,不约而同的都指向了斯坦福大学的Andrew Ng在coursera上的关于机器学习的入门基础视频教程

https://www.coursera.org/learn/machine-learning

(好吧,翻墙实在是慢,最近由于我们的XXX,搞的梯子都不好用了,推荐下[b站的搬运视频](https://www.bilibili.com/video/av9912938/)[而且翻译比coursera全面])


但我看了下coursera上的课程安排,一共11周,时间太长了,打算尽可能快的学习完毕,具体速度看这几天的学习情况再定

#### 学习内容 ####

coursera第一周上半部分

1. 大致上了解了机器学习所做的领域和作用
2. 了解了监督学习( Supervised learning )和非监督学习的定义和一些例子
3. 了解了类聚算法,分类算法的作用
4. 复习了一下微积分的基础概念和简单计算

### 10.25 ###

继续coursera的课程第一周的下半部分

1. 学习了解了监督学习中的回归问题
2. 学习了解了代价函数(cost function)的定义和作用
3. 学习了解了假设函数的定义和作用
4. 学习了解了单个参数下线性回归问题(梯度下降法)的简单思考过程
5. 复习了线代中矩阵部分的基础知识

### 10.26 ###

继续coursera的课程第二周上半部分

1. 学习了解了特征缩放的使用和使用场景
2. 学习了解了归一化的使用和使用场景
3. 学习了解了多项式回归的使用
4. 了解了什么叫数据拟合
5. 初步了解了正规方程法
6. 了解了正规方程法和梯度下降法的优点和缺点,和适用的场景

### 10.27-10.28 ###

继续coursera课程第二周下半部分

1. 了解coursera的语法

### 10.29 ###

1.完成第二周编程作业:线性回归问题,并且完成了附加部分(多参数)


### 10.30-11.5 ###

有事在忙,现在还没更新,进度比原来慢了点,因为有几天有事. 

### 11.6-11.7 ###

>小手术住院啦,进度慢了点

完成coursera的课程第三周的学习

1. 学习了解了二元分类算法
2. 学习了解了多元分类算法
3. 了解了一些高级的优化算法的使用

### 11.8 ###

随便找个博客,开始入手了解下推荐系统(我也不知道这个毕业设计本质上是不是推荐系统,个人觉得挺像)

[基于内容的推荐（Content-based Recommendations）](https://www.cnblogs.com/breezedeus/archive/2012/04/10/2440488.html)


[协同过滤算法](http://blog.csdn.net/acdreamers/article/details/44672305) 


### 11.9 ###

学习了coursera的过拟合部分


### 11.11 ###

了解了简单的神经网络相关内容,好难.

### 11.12 ###

最近感觉状态不好,调整学习状态,在看一些入门科普性质的博文


[一入侯门“深”似海，深度学习深几许（深度学习入门系列之一）](https://yq.aliyun.com/articles/86580?spm=5176.100239.blogcont159710.14.CEFeKZ)

[人工“碳”索意犹尽，智能“硅”来未可知（深度学习入门系列之二）](https://yq.aliyun.com/articles/88300?spm=5176.100239.blogcont159710.15.CEFeKZ)



### 11.13 ###

[神经网络不胜语，M-P模型似可寻（深度学习入门系列之三）](https://yq.aliyun.com/articles/90565?spm=5176.100239.blogcont159710.16.CEFeKZ)

[“机器学习”三重门，“中庸之道”趋若人（深度学习入门系列之四）](https://yq.aliyun.com/articles/91436?spm=5176.100239.blogcont159710.17.CEFeKZ)

[Hello World感知机，懂你我心才安息 (深度学习入门系列之五)](https://yq.aliyun.com/articles/93540?spm=5176.100239.blogcont159710.18.CEFeKZ)

### 11.14 ###

[损失函数减肥用，神经网络调权重（深度学习入门系列之六）](https://yq.aliyun.com/articles/96427?spm=5176.100239.blogcont159710.19.CEFeKZ)


[山重水复疑无路，最快下降问梯度（深度学习入门系列之七）](https://yq.aliyun.com/articles/105339?spm=5176.100239.blogcont159710.20.CEFeKZ)


[BP算法双向传，链式求导最缠绵（深度学习入门系列之八）](https://yq.aliyun.com/articles/110025?spm=5176.100239.blogcont159710.21.CEFeKZ)


[全面连接困何处，卷积网络见解深（深度学习入门系列之九）](https://yq.aliyun.com/articles/152935?spm=5176.100239.blogcont159710.22.CEFeKZ)


[卷地风来忽吹散，积得飘零美如画（深度学习入门系列之十）](https://yq.aliyun.com/articles/156269?spm=5176.100239.blogcont159710.23.CEFeKZ)

[局部连接来减参，权值共享肩并肩（深度学习入门系列之十一） ](https://yq.aliyun.com/articles/159710?spm=5176.100239.blogcont156269.36.gi4U7M)


### 11.15 ###

[激活引入非线性，池化预防过拟合（深度学习入门系列之十二） ](https://yq.aliyun.com/articles/167391?spm=5176.100239.blogcont159710.38.tOyt1T)

[循环递归RNN，序列建模套路深（深度学习入门系列之十三） ](https://yq.aliyun.com/articles/169880?spm=5176.100239.blogcont167391.45.HProlG)

[LSTM长短记，长序依赖可追忆（深度学习入门系列之十四） ](https://yq.aliyun.com/articles/174256?spm=5176.100239.blogcont169880.49.zcgJVE)


### 11.16-11.19 ###

休息

### 11.20 ###

去github上找了一天的爬虫,然而没几个能用的,不过学到了点东西,准备自己写

### 11.21 ###

入门py,我并不打算花很长时间学习,我直接选了廖学峰的py教程

https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000

预计花一个周左右

### 11.22-11.25 ###

学习完py的基本语法

### 11.26 ###

学习了下爬虫框架scrapy的使用

### 11.27 ###

想偷懒上github找爬虫的,后来发现都不合乎自己的要求,浪费了一天

### 11.28-11.29 ###

开始自己写爬虫,具体进程我明天再在github上新建个工程.