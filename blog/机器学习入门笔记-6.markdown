# 前言 #

这次笔记是针对**过拟合**现象的笔记,第几周我就不知道了,由于最近梯子不好用,我转战b站的搬运视频了从7-1开始


主要说明什么是过拟合,怎么解决等

# 什么是过拟合 #

我们先来个百度的概念:
>过拟合是指为了得到一致假设而使假设变得过度严格。

看不懂吧,我也看不懂,我们再来看个视频里的例子

这个是一个二元分类的问题

![](https://i.imgur.com/ZPKKXbD.png)

### 第一个图: ###

如果我们使用的只是每个特征量的一次方,一个十分简单的模型去拟合

结果就是,不能很好的拟合我们的数据(你说为什么不能很好..我只能说目前我的水平只能说是感觉的出来,反正中间那个拟合的稍微好一点)

这个叫做 **欠拟合现象**


### 第二个图: ###

如果我们使用每个特征量的二次方和他们之间的组合,去拟合我们的数据

结果看起来还是可以的


### 第三个图: ###

如果我们使用特别复杂的模型去拟合我们的数据

结果就是...你自己看那个决策边界..这个是一个很明显的**过拟合现象**,个人理解过拟合的话,就是说由于算法为了尽可能的拟合你给的假设模型,所以会出现这种情况,过拟合现象会使得你的模型失去一般性

这样理解的话,减轻过拟合现象的办法暂时我可以想到的有:

1. 使用简单一些的假设模型
2. 减少参数


# 如何解决(减缓)过拟合 #

我们来看看视频里吴大大怎么说的吧

1. 减少选取的变量数量
	1. 人工选出合适的变量
	2. 使用模型选择算法去筛选(自动的哦)
	3. 缺点:舍弃了问题的一些信息
2. 正则化(regularzation)



# 正则化 #

正规化,怎么解释我不好说,但看了吴大大的视频后,有了一个比较直观的感受,在我个人看来,正规化做的事情就是在计算代价函数的时候,适度的减少了训练集的数据对代价函数值的影响,从而不那么的'拟合'我们的训练集数据.

我们先来看一下之前学的线性回归问题中的代价函数正则化之后是什么样的


![](https://i.imgur.com/5YE5hPU.png)

为了对比,下面这个是原来的代价函数的样子

![](https://i.imgur.com/PdNHEEr.png)


我们可以看到,正则化所做的事情就是咋每次累加计算代价的时候,都加上一个式子![](https://i.imgur.com/jZwhlFx.png)平衡与之前累加计算出来的代价,这样做就减轻了累加计算出来的代价对最终的代价值的影响.**(如果你看不懂我说的啥,你可以自己假设一下γ你取一个很大的数字,那这个代价函数最终就类似一个常数了)**


### 注意 ###

默认情况下,我们不惩罚theta0

## 正则化参数 ##

式子里的γ就是正则化参数,控制在两个目标中的平衡关系(即累加计算出来的代价和保持这个参数值较小),就是这种平衡,能减少或者说缓和过拟合现象的出现


## 梯度下降算法(正则化) ##

既然正则化修改了我们的代价函数,那对于我们梯度下降算法肯定也会有所调整(然而其实还是一样).

我们来看下线性回归问题的梯度下降算法使用正则化是什么样的结果

![](https://i.imgur.com/6z89xxK.png)

可以看到除了theta0(前面说过默认情况下不会惩罚theta0),其他的每次计算的时候,都加了一个新的式子,用于平衡作用.

其实这个式子就是通过前面的代价函数求导而得的,所以其实我们的梯度下降算法思路没有改变.

## 正规方程(正则化) ##

我们再来看一下正则化对之前的正规方程求解线性回归问题的改变


![](https://i.imgur.com/P6HRlFP.png)


我们可以看到,这回直接用正规方程的计算过程已经有所不同.

